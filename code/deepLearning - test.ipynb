{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d6277b78-04f0-4cb6-b32b-7ccb718f36d9",
   "metadata": {},
   "source": [
    "# Lie detector\n",
    "#### CNN model\n",
    "\n",
    "> Mayur Sharma\\\n",
    "> Rohan deep Kujur\\\n",
    "> Khushi Tulsian\\\n",
    "> Atharva Karve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af805449-d5f3-45a7-aa8a-0b8627bdc959",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import GroupShuffleSplit\n",
    "\n",
    "pd.set_option('display.max_rows', 50)\n",
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85fdac5a-1b65-4fe8-acd7-35c50a825130",
   "metadata": {},
   "source": [
    "# Import and Combine datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "002a382e-94f3-4ad6-848d-6d9fb23ed46f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Segments viewer\n",
    "N = 3\n",
    "candidate = pd.read_csv(rf'.\\data\\VID{N}_data.csv')\n",
    "i = 1\n",
    "for group in candidate.groupby(\"question_no\"):\n",
    "    print(i, len(group[1]))\n",
    "    i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b214fae-1f67-4e8e-ae89-ae839d3e36b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "lie_data = pd.DataFrame([])\n",
    "\n",
    "for i in (1,2,3,5):\n",
    "    candidate = pd.read_csv(rf'.\\data\\VID{i}_data.csv')\n",
    "    print(candidate.shape)\n",
    "    # change Q\n",
    "    candidate['question_no'] = i + 0.01*candidate['question_no']\n",
    "    \n",
    "    lie_data  = pd.concat( [lie_data, candidate] )\n",
    "\n",
    "print(lie_data.shape)\n",
    "print(\"T:\",lie_data[lie_data[\"TRUTH\"] == 0].shape[0])\n",
    "print(\"F:\", lie_data[lie_data[\"TRUTH\"] == 1].shape[0])\n",
    "lie_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6b6dafc-1361-4533-96fa-ddbb4d2fd1b3",
   "metadata": {},
   "source": [
    "# cleaning dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21489306-cedb-4b59-867e-4c4fc7bbce1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def consecutive_difference(df):\n",
    "    diff_columns = lie_data.columns[1:28]\n",
    "\n",
    "    df.sort_values(['frame'], inplace=True)\n",
    "    grouped = df.groupby(['question_no'])\n",
    "    df[diff_columns] = grouped[diff_columns].diff()\n",
    "    df.dropna(inplace=True)\n",
    "\n",
    "\n",
    "def group_split(X, y, group, train_size = 0.8):\n",
    "    splitter = GroupShuffleSplit(train_size = train_size)\n",
    "    train, test = next(splitter.split(X, y, groups = group))\n",
    "    return (X.iloc[train], X.iloc[test], y.iloc[train], y.iloc[test])"
   ]
  },
  {
   "cell_type": "raw",
   "id": "94765104-b713-4fdc-88e5-4cf9ef624d81",
   "metadata": {},
   "source": [
    "## to calculate difference in consecutive frames (HIDDEN)\n",
    "consecutive_difference(lie_data)\n",
    "print(lie_data.shape)\n",
    "lie_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "217ec4ff-770c-49a0-a3e9-defd886487d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "lie_data = lie_data.sample(frac=1)\n",
    "\n",
    "X = lie_data.copy().dropna()\n",
    "question_no = X['question_no']\n",
    "\n",
    "X = X.drop(['frame', 'question_no'], axis=1)\n",
    "y = X.pop('TRUTH')\n",
    "\n",
    "# X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f4ec939-a0b1-45b2-a1a9-5392b0b8e31c",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_valid, y_train, y_valid = group_split(X, y, question_no)\n",
    "\n",
    "print(\"\\n\\tDATABASE\")\n",
    "print(X.shape)\n",
    "print(\"TRUE :\", lie_data[ lie_data['TRUTH'] == 1 ].shape[0])\n",
    "print(\"FALSE:\", lie_data[ lie_data['TRUTH'] == 0 ].shape[0])\n",
    "\n",
    "print(\"\\n\\tTRAIN\")\n",
    "print(X_train.shape)\n",
    "print(\"TRUE :\", sum(y_train == 1 ) )\n",
    "print(\"FALSE:\", sum(y_train == 0 ) )\n",
    "\n",
    "print(\"\\n\\tTEST\")\n",
    "print(X_valid.shape)\n",
    "print(\"TRUE :\", sum(y_valid == 1 ) )\n",
    "print(\"FALSE:\", sum(y_valid == 0 ) )\n",
    "# X_train\n",
    "# X_valid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f65faa3-9f95-430a-8364-e5b0ff84d94e",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_shape = X.shape[1]\n",
    "input_shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ce7d303-27c9-427c-a195-c1cbf12c5c3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from keras import layers, activations, losses, metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbdb355d-2e89-436d-8dd6-3fbe93fae650",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.Sequential([\n",
    "    layers.Dense(64, activation='relu', input_shape=(input_shape,)),\n",
    "    layers.BatchNormalization(),\n",
    "    layers.Dropout(0.3),\n",
    "    \n",
    "    layers.Dense(32, activation='relu'),\n",
    "    layers.BatchNormalization(),\n",
    "    layers.Dropout(0.3),\n",
    "    \n",
    "    layers.Dense(1, activation=None)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19d3f1ae-9c4e-43fc-a3dd-30c831cdb682",
   "metadata": {},
   "outputs": [],
   "source": [
    "adam = tf.keras.optimizers.Adam(learning_rate=0.1)\n",
    "\n",
    "model.compile(\n",
    "    optimizer = adam,\n",
    "    loss    = losses.BinaryCrossentropy(from_logits=True),\n",
    "    metrics = [metrics.BinaryAccuracy()]\n",
    ")\n",
    "\n",
    "early_stopping = keras.callbacks.EarlyStopping(\n",
    "    patience  = 40,\n",
    "    min_delta = 0.001,\n",
    "    restore_best_weights=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b628e51c-f345-4ec9-a573-4411c30ba1ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(\n",
    "    X_train, y_train,\n",
    "    validation_data=(X_valid, y_valid),\n",
    "    batch_size = 16,\n",
    "    epochs = 128,\n",
    "    # callbacks=[early_stopping],\n",
    ")\n",
    "\n",
    "history_df = pd.DataFrame(history.history)\n",
    "history_df.loc[:, ['loss', 'val_loss']].plot(title=\"Cross-entropy\")\n",
    "history_df.loc[:, ['binary_accuracy', 'val_binary_accuracy']].plot(title=\"Accuracy\", ylim=[-0.1, 1.1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ff0f32e-f2bb-4d09-9a93-1f6d6018175e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12821604-2095-4531-b1e9-29e4208cebbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "history_df.loc[:, ['loss', 'val_loss']].plot(title=\"Cross-entropy\")\n",
    "plt.savefig(\"cross-entropy.png\")\n",
    "history_df.loc[:, ['binary_accuracy', 'val_binary_accuracy']].plot(title=\"Accuracy\", ylim=[-0.1, 1.1])\n",
    "plt.savefig(\"accuracy.png\")"
   ]
  },
  {
   "cell_type": "raw",
   "id": "1bd7d21a-2639-4e2d-ae2d-9495db6c09b4",
   "metadata": {},
   "source": [
    "sequential_data = []  # this is a list that will CONTAIN the sequences\n",
    "prev_days = deque(maxlen=SEQ_LEN)  # These will be our actual sequences. They are made with deque, which keeps the maximum length by popping out older values as new ones come in\n",
    "\n",
    "for i in df.values:  # iterate over the values\n",
    "    prev_days.append([n for n in i[:-1]])  # store all but the target\n",
    "    if len(prev_days) == SEQ_LEN:  # make sure we have 60 sequences!\n",
    "        sequential_data.append([np.array(prev_days), i[-1]])  # append those bad boys!\n",
    "\n",
    "random.shuffle(sequential_data)  # shuffle for good measure."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bea5ebf0-79f5-4288-ae25-03f404bdc2a9",
   "metadata": {},
   "source": [
    "# PAST"
   ]
  },
  {
   "cell_type": "raw",
   "id": "f94753f5-bf34-4a35-a30d-1dc2ad856709",
   "metadata": {},
   "source": [
    "import matplotlib.pyplot as plt\n",
    "history_df.loc[:, ['loss', 'val_loss']].plot(title=\"Cross-entropy\")\n",
    "\n",
    "plt.savefig('b.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "696d9b06-1779-4543-b2c7-4c9169bf8737",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deepLearn",
   "language": "python",
   "name": "deeplearn"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
