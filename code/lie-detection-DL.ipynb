{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2024-02-23T06:00:11.524301Z",
     "iopub.status.busy": "2024-02-23T06:00:11.523438Z",
     "iopub.status.idle": "2024-02-23T06:00:11.534053Z",
     "shell.execute_reply": "2024-02-23T06:00:11.532904Z",
     "shell.execute_reply.started": "2024-02-23T06:00:11.524248Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\tulsi\\AppData\\Local\\Temp\\ipykernel_16692\\1321570591.py:6: DeprecationWarning: \n",
      "Pyarrow will become a required dependency of pandas in the next major release of pandas (pandas 3.0),\n",
      "(to allow more performant data types, such as the Arrow string type, and better interoperability with other libraries)\n",
      "but was not found to be installed on your system.\n",
      "If this would cause problems for you,\n",
      "please provide us feedback at https://github.com/pandas-dev/pandas/issues/54466\n",
      "        \n",
      "  import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n"
     ]
    }
   ],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "\n",
    "\n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-23T06:00:11.813148Z",
     "iopub.status.busy": "2024-02-23T06:00:11.810764Z",
     "iopub.status.idle": "2024-02-23T06:00:11.862320Z",
     "shell.execute_reply": "2024-02-23T06:00:11.860717Z",
     "shell.execute_reply.started": "2024-02-23T06:00:11.813092Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lipsx</th>\n",
       "      <th>lipsy</th>\n",
       "      <th>left_browx</th>\n",
       "      <th>left_browy</th>\n",
       "      <th>right_browx</th>\n",
       "      <th>right_browy</th>\n",
       "      <th>body0x</th>\n",
       "      <th>body0y</th>\n",
       "      <th>body1x</th>\n",
       "      <th>body1y</th>\n",
       "      <th>...</th>\n",
       "      <th>body7y</th>\n",
       "      <th>face0x</th>\n",
       "      <th>face0y</th>\n",
       "      <th>face1x</th>\n",
       "      <th>face1y</th>\n",
       "      <th>face2x</th>\n",
       "      <th>face2y</th>\n",
       "      <th>face3x</th>\n",
       "      <th>face3y</th>\n",
       "      <th>TRUTH</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.001107</td>\n",
       "      <td>0.031804</td>\n",
       "      <td>-0.053075</td>\n",
       "      <td>-0.033591</td>\n",
       "      <td>0.060648</td>\n",
       "      <td>-0.029370</td>\n",
       "      <td>0.244749</td>\n",
       "      <td>-0.003385</td>\n",
       "      <td>-0.244749</td>\n",
       "      <td>0.003385</td>\n",
       "      <td>...</td>\n",
       "      <td>0.544281</td>\n",
       "      <td>0.008663</td>\n",
       "      <td>-0.040341</td>\n",
       "      <td>-0.004295</td>\n",
       "      <td>0.063091</td>\n",
       "      <td>-0.080905</td>\n",
       "      <td>0.017946</td>\n",
       "      <td>0.079827</td>\n",
       "      <td>0.023363</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.001794</td>\n",
       "      <td>0.030796</td>\n",
       "      <td>-0.052959</td>\n",
       "      <td>-0.032074</td>\n",
       "      <td>0.059244</td>\n",
       "      <td>-0.029025</td>\n",
       "      <td>0.246057</td>\n",
       "      <td>-0.003136</td>\n",
       "      <td>-0.246057</td>\n",
       "      <td>0.003136</td>\n",
       "      <td>...</td>\n",
       "      <td>0.544409</td>\n",
       "      <td>0.007592</td>\n",
       "      <td>-0.037885</td>\n",
       "      <td>-0.004266</td>\n",
       "      <td>0.061061</td>\n",
       "      <td>-0.079106</td>\n",
       "      <td>0.019367</td>\n",
       "      <td>0.077311</td>\n",
       "      <td>0.023393</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.002718</td>\n",
       "      <td>0.031074</td>\n",
       "      <td>-0.054027</td>\n",
       "      <td>-0.032401</td>\n",
       "      <td>0.058203</td>\n",
       "      <td>-0.028548</td>\n",
       "      <td>0.246974</td>\n",
       "      <td>-0.002954</td>\n",
       "      <td>-0.246974</td>\n",
       "      <td>0.002954</td>\n",
       "      <td>...</td>\n",
       "      <td>0.545489</td>\n",
       "      <td>0.006395</td>\n",
       "      <td>-0.037179</td>\n",
       "      <td>-0.006021</td>\n",
       "      <td>0.060508</td>\n",
       "      <td>-0.081213</td>\n",
       "      <td>0.019012</td>\n",
       "      <td>0.075062</td>\n",
       "      <td>0.023403</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.002734</td>\n",
       "      <td>0.031018</td>\n",
       "      <td>-0.053086</td>\n",
       "      <td>-0.032754</td>\n",
       "      <td>0.059224</td>\n",
       "      <td>-0.028536</td>\n",
       "      <td>0.247235</td>\n",
       "      <td>-0.002925</td>\n",
       "      <td>-0.247235</td>\n",
       "      <td>0.002925</td>\n",
       "      <td>...</td>\n",
       "      <td>0.545792</td>\n",
       "      <td>0.007735</td>\n",
       "      <td>-0.037539</td>\n",
       "      <td>-0.006494</td>\n",
       "      <td>0.060074</td>\n",
       "      <td>-0.080609</td>\n",
       "      <td>0.018408</td>\n",
       "      <td>0.075682</td>\n",
       "      <td>0.023359</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.002798</td>\n",
       "      <td>0.030957</td>\n",
       "      <td>-0.052412</td>\n",
       "      <td>-0.032349</td>\n",
       "      <td>0.058886</td>\n",
       "      <td>-0.028198</td>\n",
       "      <td>0.247395</td>\n",
       "      <td>-0.002847</td>\n",
       "      <td>-0.247395</td>\n",
       "      <td>0.002847</td>\n",
       "      <td>...</td>\n",
       "      <td>0.545749</td>\n",
       "      <td>0.007852</td>\n",
       "      <td>-0.037106</td>\n",
       "      <td>-0.006559</td>\n",
       "      <td>0.060057</td>\n",
       "      <td>-0.080242</td>\n",
       "      <td>0.018465</td>\n",
       "      <td>0.075385</td>\n",
       "      <td>0.023527</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      lipsx     lipsy  left_browx  left_browy  right_browx  right_browy  \\\n",
       "0 -0.001107  0.031804   -0.053075   -0.033591     0.060648    -0.029370   \n",
       "1 -0.001794  0.030796   -0.052959   -0.032074     0.059244    -0.029025   \n",
       "2 -0.002718  0.031074   -0.054027   -0.032401     0.058203    -0.028548   \n",
       "3 -0.002734  0.031018   -0.053086   -0.032754     0.059224    -0.028536   \n",
       "4 -0.002798  0.030957   -0.052412   -0.032349     0.058886    -0.028198   \n",
       "\n",
       "     body0x    body0y    body1x    body1y  ...    body7y    face0x    face0y  \\\n",
       "0  0.244749 -0.003385 -0.244749  0.003385  ...  0.544281  0.008663 -0.040341   \n",
       "1  0.246057 -0.003136 -0.246057  0.003136  ...  0.544409  0.007592 -0.037885   \n",
       "2  0.246974 -0.002954 -0.246974  0.002954  ...  0.545489  0.006395 -0.037179   \n",
       "3  0.247235 -0.002925 -0.247235  0.002925  ...  0.545792  0.007735 -0.037539   \n",
       "4  0.247395 -0.002847 -0.247395  0.002847  ...  0.545749  0.007852 -0.037106   \n",
       "\n",
       "     face1x    face1y    face2x    face2y    face3x    face3y  TRUTH  \n",
       "0 -0.004295  0.063091 -0.080905  0.017946  0.079827  0.023363      1  \n",
       "1 -0.004266  0.061061 -0.079106  0.019367  0.077311  0.023393      1  \n",
       "2 -0.006021  0.060508 -0.081213  0.019012  0.075062  0.023403      1  \n",
       "3 -0.006494  0.060074 -0.080609  0.018408  0.075682  0.023359      1  \n",
       "4 -0.006559  0.060057 -0.080242  0.018465  0.075385  0.023527      1  \n",
       "\n",
       "[5 rows x 31 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df =pd.read_csv(\"E:/NMIMS work/Project/lie-detection/code/previous-MLcode/lie_dataset.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-23T06:02:20.119273Z",
     "iopub.status.busy": "2024-02-23T06:02:20.118821Z",
     "iopub.status.idle": "2024-02-23T06:02:20.131484Z",
     "shell.execute_reply": "2024-02-23T06:02:20.129585Z",
     "shell.execute_reply.started": "2024-02-23T06:02:20.119243Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "30"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = df.copy()\n",
    "y = X.pop(\"TRUTH\")\n",
    "\n",
    "input_shape = X.shape[1]\n",
    "input_shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-23T06:02:20.828602Z",
     "iopub.status.busy": "2024-02-23T06:02:20.828224Z",
     "iopub.status.idle": "2024-02-23T06:02:20.833982Z",
     "shell.execute_reply": "2024-02-23T06:02:20.832546Z",
     "shell.execute_reply.started": "2024-02-23T06:02:20.828573Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-23T06:02:21.357836Z",
     "iopub.status.busy": "2024-02-23T06:02:21.357152Z",
     "iopub.status.idle": "2024-02-23T06:02:21.368051Z",
     "shell.execute_reply": "2024-02-23T06:02:21.366875Z",
     "shell.execute_reply.started": "2024-02-23T06:02:21.357800Z"
    }
   },
   "outputs": [],
   "source": [
    "X_train, X_valid, y_train, y_valid = train_test_split(X, y, stratify=y, train_size=0.6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-23T06:02:22.028966Z",
     "iopub.status.busy": "2024-02-23T06:02:22.028547Z",
     "iopub.status.idle": "2024-02-23T06:02:22.035735Z",
     "shell.execute_reply": "2024-02-23T06:02:22.034259Z",
     "shell.execute_reply.started": "2024-02-23T06:02:22.028933Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From E:\\NMIMS work\\Project\\lie-detection\\code\\lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, LSTM, BatchNormalization\n",
    "from tensorflow.keras.callbacks import TensorBoard,ModelCheckpoint ## To save best accuracy or loss as a checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-23T06:02:22.470058Z",
     "iopub.status.busy": "2024-02-23T06:02:22.468614Z",
     "iopub.status.idle": "2024-02-23T06:02:22.474653Z",
     "shell.execute_reply": "2024-02-23T06:02:22.473285Z",
     "shell.execute_reply.started": "2024-02-23T06:02:22.470008Z"
    }
   },
   "outputs": [],
   "source": [
    "#X_train = np.reshape(X_train, (X_train.shape[0],1,X_train.shape[1]))\n",
    "#X_valid = np.reshape(X_valid, (X_valid.shape[0],1,X_valid.shape[1]))\n",
    "#X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-23T06:02:22.990071Z",
     "iopub.status.busy": "2024-02-23T06:02:22.989625Z",
     "iopub.status.idle": "2024-02-23T06:02:24.020179Z",
     "shell.execute_reply": "2024-02-23T06:02:24.018835Z",
     "shell.execute_reply.started": "2024-02-23T06:02:22.990036Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From E:\\NMIMS work\\Project\\lie-detection\\code\\lib\\site-packages\\keras\\src\\backend.py:873: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(LSTM(128, input_shape=X_train.shape, return_sequences=True))\n",
    "model.add(Dropout(0.2))\n",
    "#model.add(BatchNormalization())  #normalizes activation outputs, same reason you want to normalize your input data.\n",
    "\n",
    "model.add(LSTM(128, return_sequences=True))\n",
    "model.add(Dropout(0.1))\n",
    "#model.add(BatchNormalization())\n",
    "\n",
    "model.add(LSTM(128))\n",
    "model.add(Dropout(0.2))\n",
    "#model.add(BatchNormalization())\n",
    "\n",
    "model.add(Dense(32, activation='relu'))\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "model.add(Dense(2, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-23T06:02:24.022420Z",
     "iopub.status.busy": "2024-02-23T06:02:24.021963Z",
     "iopub.status.idle": "2024-02-23T06:02:24.038204Z",
     "shell.execute_reply": "2024-02-23T06:02:24.036614Z",
     "shell.execute_reply.started": "2024-02-23T06:02:24.022387Z"
    }
   },
   "outputs": [],
   "source": [
    "opt = tf.keras.optimizers.Adam()\n",
    "\n",
    "# Compile model\n",
    "model.compile(\n",
    "    loss='categorical_crossentropy',\n",
    "    optimizer=opt,\n",
    "    metrics=['accuracy']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-23T06:02:24.093831Z",
     "iopub.status.busy": "2024-02-23T06:02:24.093376Z",
     "iopub.status.idle": "2024-02-23T06:02:24.102554Z",
     "shell.execute_reply": "2024-02-23T06:02:24.100400Z",
     "shell.execute_reply.started": "2024-02-23T06:02:24.093797Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(189,)\n",
      "(189, 30)\n",
      "(126, 30)\n",
      "(126,)\n"
     ]
    }
   ],
   "source": [
    "print(y_train.shape)\n",
    "print(X_train.shape)\n",
    "print(X_valid.shape)\n",
    "print(y_valid.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-23T06:02:27.251132Z",
     "iopub.status.busy": "2024-02-23T06:02:27.250681Z",
     "iopub.status.idle": "2024-02-23T06:02:27.415414Z",
     "shell.execute_reply": "2024-02-23T06:02:27.413802Z",
     "shell.execute_reply.started": "2024-02-23T06:02:27.251101Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "in user code:\n\n    File \"/opt/conda/lib/python3.10/site-packages/keras/src/engine/training.py\", line 1401, in train_function  *\n        return step_function(self, iterator)\n    File \"/opt/conda/lib/python3.10/site-packages/keras/src/engine/training.py\", line 1384, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/opt/conda/lib/python3.10/site-packages/keras/src/engine/training.py\", line 1373, in run_step  **\n        outputs = model.train_step(data)\n    File \"/opt/conda/lib/python3.10/site-packages/keras/src/engine/training.py\", line 1150, in train_step\n        y_pred = self(x, training=True)\n    File \"/opt/conda/lib/python3.10/site-packages/keras/src/utils/traceback_utils.py\", line 70, in error_handler\n        raise e.with_traceback(filtered_tb) from None\n    File \"/opt/conda/lib/python3.10/site-packages/keras/src/engine/input_spec.py\", line 298, in assert_input_compatibility\n        raise ValueError(\n\n    ValueError: Input 0 of layer \"sequential_4\" is incompatible with the layer: expected shape=(None, 189, 30), found shape=(None, 30)\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[56], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m history \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      2\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m64\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[43m    \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m100\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mX_valid\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_valid\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m#callbacks=[tensorboard, checkpoint],\u001b[39;49;00m\n\u001b[1;32m      7\u001b[0m \u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/keras/src/utils/traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[1;32m     68\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[1;32m     69\u001b[0m     \u001b[38;5;66;03m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[0;32m---> 70\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     71\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m     72\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m/tmp/__autograph_generated_fileh4331zj6.py:15\u001b[0m, in \u001b[0;36mouter_factory.<locals>.inner_factory.<locals>.tf__train_function\u001b[0;34m(iterator)\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     14\u001b[0m     do_return \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m---> 15\u001b[0m     retval_ \u001b[38;5;241m=\u001b[39m ag__\u001b[38;5;241m.\u001b[39mconverted_call(ag__\u001b[38;5;241m.\u001b[39mld(step_function), (ag__\u001b[38;5;241m.\u001b[39mld(\u001b[38;5;28mself\u001b[39m), ag__\u001b[38;5;241m.\u001b[39mld(iterator)), \u001b[38;5;28;01mNone\u001b[39;00m, fscope)\n\u001b[1;32m     16\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m:\n\u001b[1;32m     17\u001b[0m     do_return \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "\u001b[0;31mValueError\u001b[0m: in user code:\n\n    File \"/opt/conda/lib/python3.10/site-packages/keras/src/engine/training.py\", line 1401, in train_function  *\n        return step_function(self, iterator)\n    File \"/opt/conda/lib/python3.10/site-packages/keras/src/engine/training.py\", line 1384, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/opt/conda/lib/python3.10/site-packages/keras/src/engine/training.py\", line 1373, in run_step  **\n        outputs = model.train_step(data)\n    File \"/opt/conda/lib/python3.10/site-packages/keras/src/engine/training.py\", line 1150, in train_step\n        y_pred = self(x, training=True)\n    File \"/opt/conda/lib/python3.10/site-packages/keras/src/utils/traceback_utils.py\", line 70, in error_handler\n        raise e.with_traceback(filtered_tb) from None\n    File \"/opt/conda/lib/python3.10/site-packages/keras/src/engine/input_spec.py\", line 298, in assert_input_compatibility\n        raise ValueError(\n\n    ValueError: Input 0 of layer \"sequential_4\" is incompatible with the layer: expected shape=(None, 189, 30), found shape=(None, 30)\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(\n",
    "    X_train, y_train,\n",
    "    batch_size=64,\n",
    "    epochs=100,\n",
    "    validation_data=(X_valid, y_valid)\n",
    "    #callbacks=[tensorboard, checkpoint],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "datasetId": 4482297,
     "sourceId": 7682405,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30646,
   "isGpuEnabled": false,
   "isInternetEnabled": false,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "deepLearn",
   "language": "python",
   "name": "deeplearn"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
