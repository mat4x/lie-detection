{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0a0115c4-be04-454e-abc5-e4da5a619e30",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From N:\\Mayur\\Programming\\GitHub\\lie-detection\\code\\lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import mediapipe as mp\n",
    "import numpy as np\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ba11d6c5-bad9-4702-aa93-d73c7235bdc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "mp_drawing  = mp.solutions.drawing_utils\n",
    "\n",
    "mp_face_detection = mp.solutions.face_detection\n",
    "face_detection = mp_face_detection.FaceDetection()\n",
    "\n",
    "mp_face_mesh = mp.solutions.face_mesh\n",
    "face_mesh    = mp_face_mesh.FaceMesh()\n",
    "\n",
    "mp_holistic = mp.solutions.holistic\n",
    "holistic    = mp_holistic.Holistic()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1da89512-4c9f-4c19-9f8b-60e9987c2754",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Holistic\n",
    "def draw_facemarks(image, results):\n",
    "    mp_drawing.draw_landmarks(\n",
    "        image         = image,\n",
    "        landmark_list = results.face_landmarks,\n",
    "        #connections   = mp_holistic.FACEMESH_CONTOURS,\n",
    "        \n",
    "        landmark_drawing_spec = mp_drawing.DrawingSpec(\n",
    "                                    color=(0,2,255),\n",
    "                                    thickness=1,\n",
    "                                    circle_radius=2),\n",
    "        \n",
    "        connection_drawing_spec = mp_drawing.DrawingSpec(\n",
    "                                color=(128,128,128),\n",
    "                                thickness=1,\n",
    "                                circle_radius=1)\n",
    "        )\n",
    "\n",
    "# Holistic\n",
    "def draw_posemarks(image, results):\n",
    "    mp_drawing.draw_landmarks(\n",
    "        image = image,\n",
    "        landmark_list = results.pose_landmarks,\n",
    "        connections   = mp_holistic.POSE_CONNECTIONS,\n",
    "        \n",
    "        landmark_drawing_spec = mp_drawing.DrawingSpec(\n",
    "            color=(0,230,255),\n",
    "            thickness=2,\n",
    "            circle_radius=1),\n",
    "        \n",
    "        connection_drawing_spec = mp_drawing.DrawingSpec(\n",
    "            color=(255,255,255),\n",
    "            thickness=1,\n",
    "            circle_radius=1)\n",
    "        )\n",
    "\n",
    "# FaceMesh\n",
    "def draw_face_landmarks(image, results):\n",
    "    if not results.multi_face_landmarks:\n",
    "        return\n",
    "    for face_landmark in results.multi_face_landmarks:\n",
    "        mp_drawing.draw_landmarks(\n",
    "            image = image,\n",
    "            landmark_list = face_landmark,\n",
    "            connections   = mp_face_mesh.FACEMESH_TESSELATION,\n",
    "\n",
    "            landmark_drawing_spec = mp_drawing.DrawingSpec(\n",
    "                color=(255,0,0),\n",
    "                thickness=2,\n",
    "                circle_radius=1),\n",
    "            \n",
    "            connection_drawing_spec = mp_drawing.DrawingSpec(\n",
    "                color=(255,255,255),\n",
    "                thickness=1,\n",
    "                circle_radius=1)\n",
    "        )\n",
    "\n",
    "\n",
    "def draw_face_detection(image, results):\n",
    "    if not results.detections:\n",
    "        return\n",
    "    for landmark in results.detections:\n",
    "        mp_drawing.draw_landmarks( image,landmark)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0179e302-b923-4cc2-a574-9951eedd98ab",
   "metadata": {},
   "source": [
    "#### Model select"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "08818b7e-efcc-4ec9-b434-dbc3e013314c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# change here | ONLY FOR LIVE VIDEO\n",
    "\n",
    "MODEL   = face_detection\n",
    "DRAW_FN = draw_facemarks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4df17530-e50d-4279-9f34-90c98cf76b0d",
   "metadata": {},
   "source": [
    "### Test on live video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "ef1939aa-084f-4879-ae23-5cc548a0d977",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "landmark",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[28], line 12\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m results\u001b[38;5;241m.\u001b[39mdetections:\n\u001b[0;32m     11\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m landmark \u001b[38;5;129;01min\u001b[39;00m results\u001b[38;5;241m.\u001b[39mdetections:\n\u001b[1;32m---> 12\u001b[0m         \u001b[43mmp_drawing\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdraw_landmarks\u001b[49m\u001b[43m(\u001b[49m\u001b[43mframe\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlandmark\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     13\u001b[0m \u001b[38;5;66;03m###\u001b[39;00m\n\u001b[0;32m     15\u001b[0m cv2\u001b[38;5;241m.\u001b[39mimshow(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcam\u001b[39m\u001b[38;5;124m\"\u001b[39m, frame)\n",
      "File \u001b[1;32mN:\\Mayur\\Programming\\GitHub\\lie-detection\\code\\lib\\site-packages\\mediapipe\\python\\solutions\\drawing_utils.py:160\u001b[0m, in \u001b[0;36mdraw_landmarks\u001b[1;34m(image, landmark_list, connections, landmark_drawing_spec, connection_drawing_spec, is_drawing_landmarks)\u001b[0m\n\u001b[0;32m    158\u001b[0m image_rows, image_cols, _ \u001b[38;5;241m=\u001b[39m image\u001b[38;5;241m.\u001b[39mshape\n\u001b[0;32m    159\u001b[0m idx_to_coordinates \u001b[38;5;241m=\u001b[39m {}\n\u001b[1;32m--> 160\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m idx, landmark \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(\u001b[43mlandmark_list\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlandmark\u001b[49m):\n\u001b[0;32m    161\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m ((landmark\u001b[38;5;241m.\u001b[39mHasField(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mvisibility\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m\n\u001b[0;32m    162\u001b[0m        landmark\u001b[38;5;241m.\u001b[39mvisibility \u001b[38;5;241m<\u001b[39m _VISIBILITY_THRESHOLD) \u001b[38;5;129;01mor\u001b[39;00m\n\u001b[0;32m    163\u001b[0m       (landmark\u001b[38;5;241m.\u001b[39mHasField(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpresence\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m\n\u001b[0;32m    164\u001b[0m        landmark\u001b[38;5;241m.\u001b[39mpresence \u001b[38;5;241m<\u001b[39m _PRESENCE_THRESHOLD)):\n\u001b[0;32m    165\u001b[0m     \u001b[38;5;28;01mcontinue\u001b[39;00m\n",
      "\u001b[1;31mAttributeError\u001b[0m: landmark"
     ]
    }
   ],
   "source": [
    "cam = cv2.VideoCapture(0)\n",
    "\n",
    "while True:\n",
    "    _, frame = cam.read()\n",
    "    if not _: break\n",
    "\n",
    "    results = face_detection.process(frame)    # MODEL\n",
    "    \n",
    "    ### DRAW\n",
    "    if results.detections:\n",
    "        for landmark in results.detections:\n",
    "            mp_drawing.draw_landmarks(frame, landmark)\n",
    "    ###\n",
    "    \n",
    "    cv2.imshow(\"cam\", frame)\n",
    "    key = cv2.waitKey(1)\n",
    "    if key == ord('q'):\n",
    "        break\n",
    "\n",
    "cam.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "829ead9c-407e-4fa4-ae24-04f28045f691",
   "metadata": {},
   "outputs": [],
   "source": [
    "cam.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "14572993-7286-42aa-a40e-79ac0899fa58",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "label_id: 0\n",
      "score: 0.528163731098175\n",
      "location_data {\n",
      "  format: RELATIVE_BOUNDING_BOX\n",
      "  relative_bounding_box {\n",
      "    xmin: 0.7346457242965698\n",
      "    ymin: 0.2732851505279541\n",
      "    width: 0.3400825262069702\n",
      "    height: 0.45344239473342896\n",
      "  }\n",
      "  relative_keypoints {\n",
      "    x: 0.8519724607467651\n",
      "    y: 0.3927363157272339\n",
      "  }\n",
      "  relative_keypoints {\n",
      "    x: 1.000848412513733\n",
      "    y: 0.4405812621116638\n",
      "  }\n",
      "  relative_keypoints {\n",
      "    x: 0.9214423298835754\n",
      "    y: 0.5366778373718262\n",
      "  }\n",
      "  relative_keypoints {\n",
      "    x: 0.9016500115394592\n",
      "    y: 0.6252643465995789\n",
      "  }\n",
      "  relative_keypoints {\n",
      "    x: 0.7463056445121765\n",
      "    y: 0.3863644003868103\n",
      "  }\n",
      "  relative_keypoints {\n",
      "    x: 1.0534861087799072\n",
      "    y: 0.47602754831314087\n",
      "  }\n",
      "}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(results.detections[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "568ce049-410e-4e48-8e7f-9205ece66aab",
   "metadata": {},
   "source": [
    "### Test on video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aac61c94-fb1a-469b-9264-b630513a8bba",
   "metadata": {},
   "outputs": [],
   "source": [
    "video = cv2.VideoCapture(r'.\\previous-MLcode\\Train_video.mp4')\n",
    "DIMS  = np.array([500, 880], dtype=int)      #Video crop dimension to subject\n",
    "SCALE = 0.75\n",
    "\n",
    "frame_no = 0\n",
    "\n",
    "while(1):\n",
    "    #reading video data\n",
    "    success, frame = video.read()\n",
    "    if not success: break\n",
    "    #if frame_no == 120: break     #Testing\n",
    "\n",
    "    frame_no += 1\n",
    "    #print(frame_no)\n",
    "    \n",
    "    #resizing and cropping\n",
    "    frame = frame[300:300+DIMS[1], 150:150+DIMS[0]]\n",
    "    frame = cv2.resize(frame, (0, 0), fx = SCALE, fy = SCALE)\n",
    "\n",
    "    results = holistic.process(frame)\n",
    "    draw_facemarks(frame, results)\n",
    "\n",
    "    results = face_mesh.process(frame)\n",
    "    draw_face_landmarks(frame, results)\n",
    "\n",
    "    if not bool(results.face_landmarks):\n",
    "        print(frame_no)\n",
    "        \n",
    "\n",
    "    cv2.imshow(\"video\", frame)\n",
    "    key = cv2.waitKey(1)\n",
    "    if key == ord('q'):\n",
    "        break\n",
    "\n",
    "video.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34625aa0-61fc-42e8-b4cb-42eafd6e14b9",
   "metadata": {},
   "source": [
    "### Test on image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "d03bb853-6173-468d-999d-cc4d8c650eb0",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'draw_holistics' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[38], line 5\u001b[0m\n\u001b[0;32m      1\u001b[0m image \u001b[38;5;241m=\u001b[39m cv2\u001b[38;5;241m.\u001b[39mimread(\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124msample-img\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124msample2.png\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m      4\u001b[0m results \u001b[38;5;241m=\u001b[39m holistic\u001b[38;5;241m.\u001b[39mprocess(frame)\n\u001b[1;32m----> 5\u001b[0m \u001b[43mdraw_holistics\u001b[49m(frame, results)\n\u001b[0;32m      7\u001b[0m cv2\u001b[38;5;241m.\u001b[39mimshow(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhere\u001b[39m\u001b[38;5;124m\"\u001b[39m, image)\n\u001b[0;32m      8\u001b[0m key \u001b[38;5;241m=\u001b[39m cv2\u001b[38;5;241m.\u001b[39mwaitKey(\u001b[38;5;241m0\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'draw_holistics' is not defined"
     ]
    }
   ],
   "source": [
    "image = cv2.imread(r\".\\sample-img\\sample2.png\")\n",
    "\n",
    "\n",
    "results = holistic.process(frame)\n",
    "draw_holistics(frame, results)\n",
    "\n",
    "cv2.imshow(\"here\", image)\n",
    "key = cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfb280fe-b077-4cd9-8810-0462b1f06b38",
   "metadata": {},
   "source": [
    "# HELPS:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "505317be-2313-4d07-a029-f415c0099dc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "dir(mp.solutions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3098ecb8-78f7-427d-9d10-e7d87db7a49b",
   "metadata": {},
   "outputs": [],
   "source": [
    "help(mp_drawing.draw_landmarks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e5f611d-0513-4727-b1d0-2839cf2ecf52",
   "metadata": {},
   "outputs": [],
   "source": [
    "dir(results.multi_face_landmarks[0])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deepLearn",
   "language": "python",
   "name": "deeplearn"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
