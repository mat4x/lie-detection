{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fd861fdb",
   "metadata": {},
   "source": [
    "# Lie Detection Based on Facial Expression and Body Posture\n",
    "\n",
    "> Mayur Sharma<br>\n",
    "> Khushi Tulsian<br>\n",
    "> Rohan deep Kujur<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ad51e58",
   "metadata": {},
   "outputs": [],
   "source": [
    "import mediapipe as mp\n",
    "import cv2\n",
    "from math import inf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "mp_holistic = mp.solutions.holistic\n",
    "holistic    = mp_holistic.Holistic()\n",
    "mp_drawing  = mp.solutions.drawing_utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60a78f3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# eyebrow                     x2\n",
    "# face left right top bottom  x4\n",
    "# lips                        x1\n",
    "# body                        x8\n",
    "# =15 columns     x and y     = 30 features\n",
    "\n",
    "columns0 = ['lips', 'left_brow', 'right_brow'] + [f\"body{i}\" for i in range(8)] + [f\"face{i}\" for i in range(4)] \n",
    "columns  = list()\n",
    "for col in columns0:\n",
    "    columns.append(col+'x')\n",
    "    columns.append(col+'y')\n",
    "columns.append('TRUTH')\n",
    "TRAINING_FEATURES = pd.DataFrame(columns=columns)\n",
    "TESTING_FEATURES  = pd.DataFrame(columns=columns)\n",
    "\n",
    "LANDMARKS_LOC = {\n",
    "    'left_brow'  : [107, 66, 105, 63, 70, 46,53,52,65,55],\n",
    "    'right_brow' : [336, 285, 296, 295, 334, 282, 293, 283, 276, 300],\n",
    "    'lips'       : [78, 308, 80, 88, 82, 87, 312, 317, 310, 318],\n",
    "    'face0'      : [54,68,103,104,108,69,67,10,151,338,337,397,333,332,298,284,251,301,21,71,109,297,299],                                                                       #forehead\n",
    "    'face1'      : [18, 32, 83, 140, 148, 152, 171, 175, 176, 199, 200, 201, 208, 262, 313, 369, 377, 396, 400, 421, 428],                                                       #chin\n",
    "    'face2'      : [36, 50, 58, 93, 101, 111, 116, 117, 118, 123, 132, 137, 138, 147, 172, 177, 186, 187, 192, 203, 205, 206, 207, 212, 213, 214, 215, 216, 227, 228, 234],      #left_face\n",
    "    'face3'      : [266, 280, 288, 323, 330, 340, 345, 346, 347, 352, 361, 366, 367, 376, 397, 401, 410, 411, 416, 423, 425, 426, 427, 432, 433, 434, 435, 436, 447, 448, 454]   #right_face\n",
    "}\n",
    "\n",
    "#video intervals where the subject answers\n",
    "INTERVALS = [\n",
    "    [90,  140, 1],\n",
    "    [170, 220, 1],\n",
    "    [250, 340, 0],\n",
    "    [370, 450, 1],\n",
    "    [480, 540, 1],    #TESTING INTERVAL\n",
    "    [600, 660, 0],\n",
    "    [inf, inf, 0]]\n",
    "\n",
    "TEST_INTERVAL = 3\n",
    "\n",
    "TRAINING_FEATURES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab124a2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_holistics(image, results):\n",
    "    mp_drawing.draw_landmarks( frame,\n",
    "        results.face_landmarks,\n",
    "        mp_holistic.FACEMESH_CONTOURS,\n",
    "        mp_drawing.DrawingSpec(\n",
    "            color=(255,0,255),\n",
    "            thickness=1,\n",
    "            circle_radius=1),\n",
    "        \n",
    "        mp_drawing.DrawingSpec(\n",
    "            color=(255,255,255),\n",
    "            thickness=1,\n",
    "            circle_radius=1)\n",
    "        )\n",
    "    \n",
    "    mp_drawing.draw_landmarks(\n",
    "        frame,\n",
    "        results.pose_landmarks,\n",
    "        mp_holistic.POSE_CONNECTIONS,\n",
    "        mp_drawing.DrawingSpec(\n",
    "            color=(0,230,255),\n",
    "            thickness=2,\n",
    "            circle_radius=1),\n",
    "        \n",
    "        mp_drawing.DrawingSpec(\n",
    "            color=(255,255,255),\n",
    "            thickness=1,\n",
    "            circle_radius=1)\n",
    "        )\n",
    "\n",
    "def extract_facial_features(landmarks):\n",
    "    nose = landmarks[4]  #nose at index 4\n",
    "    #x, y = get_cordinates(nose, DIMS)\n",
    "    #cv2.circle(frame, (x, y), 2, (0,0,0), 1)\n",
    "    features = dict()\n",
    "    \n",
    "    for feature in LANDMARKS_LOC:\n",
    "        feature_loc = np.array([0,0], dtype=np.float64)\n",
    "    \n",
    "        for idx in LANDMARKS_LOC[feature]:\n",
    "            mark = landmarks[idx]\n",
    "            feature_loc += np.array( [mark.x, mark.y] )\n",
    "        feature_loc /= len(LANDMARKS_LOC[feature])           #average feature location\n",
    "        \n",
    "        result = feature_loc - np.array([nose.x, nose.y])    #normailze\n",
    "        features[feature+'x'] = result[0]\n",
    "        features[feature+'y'] = result[1]\n",
    "    \n",
    "    return features\n",
    "\n",
    "def extract_body_features(landmarks):\n",
    "    chest = [(landmarks[11].x + landmarks[12].x)/2, (landmarks[11].y + landmarks[12].y)/2]\n",
    "    i = 0\n",
    "    features = dict()\n",
    "    \n",
    "    for idx in range(11,19):\n",
    "        mark = landmarks[idx]\n",
    "        features[f'body{i}x'] = mark.x - chest[0]\n",
    "        features[f'body{i}y'] = mark.y - chest[1]\n",
    "        i += 1\n",
    "    \n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b1020a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "video = cv2.VideoCapture('.\\Train_video.mp4')\n",
    "DIMS  = np.array([500, 880], dtype=int)      #Video crop dimension to subject\n",
    "SCALE = 0.75\n",
    "\n",
    "TRAINING_FEATURES.drop(TRAINING_FEATURES.index, inplace=True)\n",
    "TESTING_FEATURES.drop(TESTING_FEATURES.index, inplace=True)\n",
    "\n",
    "frame_no = 0\n",
    "curr_interval  = 0\n",
    "\n",
    "while(1):\n",
    "    #reading video data\n",
    "    success, frame = video.read()\n",
    "    if not success: break\n",
    "    #if frame_no == 90: break     #Testing\n",
    "    \n",
    "    #resizing and cropping\n",
    "    frame = frame[300:300+DIMS[1], 150:150+DIMS[0]]\n",
    "    frame = cv2.resize(frame, (0, 0), fx = SCALE, fy = SCALE)\n",
    "\n",
    "    if INTERVALS[curr_interval][0] <= frame_no <= INTERVALS[curr_interval][1]:\n",
    "        #processing body features\n",
    "        results = holistic.process( cv2.cvtColor(frame, cv2.COLOR_BGR2RGB) )\n",
    "        draw_holistics(frame, results)\n",
    "\n",
    "        face_features = extract_facial_features(results.face_landmarks.landmark)\n",
    "        body_features = extract_body_features(results.pose_landmarks.landmark)\n",
    "        #print(face_features)\n",
    "        #print(len(body_features) + len(face_features))\n",
    "\n",
    "        features = {\"TRUTH\" : INTERVALS[curr_interval][2]}\n",
    "        features.update(face_features)\n",
    "        features.update(body_features)\n",
    "        \n",
    "        #Testing interval for our code\n",
    "        if curr_interval != TEST_INTERVAL:\n",
    "            TRAINING_FEATURES = TRAINING_FEATURES.append([features])\n",
    "        else:\n",
    "            TESTING_FEATURES = TESTING_FEATURES.append([features])\n",
    "        \n",
    "        if frame_no > INTERVALS[curr_interval][1]-1:\n",
    "            curr_interval += 1\n",
    "    \n",
    "    #display results\n",
    "    cv2.imshow(\"Frame\", frame)\n",
    "    cv2.waitKey(1)\n",
    "    frame_no += 1\n",
    "\n",
    "cv2.destroyAllWindows()\n",
    "video.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc729286-f458-4715-a0f7-245f1a1d7660",
   "metadata": {},
   "outputs": [],
   "source": [
    "f1 = pd.DataFrame([[1,2,3,4,5]])\n",
    "f2 = pd.DataFrame([[1,2,3,4,5]])\n",
    "\n",
    "pd.concat([f1, f2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "958a8e9d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "TRAINING_FEATURES[\"TRUTH\"] = pd.to_numeric(TRAINING_FEATURES[\"TRUTH\"])\n",
    "TRAINING_FEATURES\n",
    "\n",
    "#TRAINING_FEATURES.to_csv(\"lie_dataset.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5b9d0a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "TRAINING_Y = TRAINING_FEATURES[\"TRUTH\"]\n",
    "TRAINING_X = TRAINING_FEATURES.drop(\"TRUTH\", axis=1)\n",
    "\n",
    "TESTING_Y = TESTING_FEATURES[\"TRUTH\"]\n",
    "TESTING_X = TESTING_FEATURES.drop(\"TRUTH\", axis=1)\n",
    "\n",
    "logr = LogisticRegression(random_state=16)\n",
    "logr = logr.fit(TRAINING_X, TRAINING_Y)\n",
    "print(TRAINING_Y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8547469",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = logr.predict(TESTING_X)\n",
    "print(f\"Expected output: {INTERVALS[TEST_INTERVAL][2]}\")\n",
    "print(\"Prediction:\\n\", y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dcd1b3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "type(TRAINING_FEATURES.corr())\n",
    "\n",
    "plt.matshow(TRAINING_FEATURES.corr())\n",
    "plt.title(\"Correlation matrix\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63faba18",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "The predicted values match the actual values, hence our model works successfully!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1898cc3d",
   "metadata": {},
   "source": [
    "### Extra Notes\n",
    "1) FACE MESH: **landmarks index 4** is the tip of the nose used for normalisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "caacd1f4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
